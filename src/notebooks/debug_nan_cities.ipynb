{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug: NaN Cities in Network\n",
    "\n",
    "This notebook investigates why the top city by TEU is showing as NaN.\n",
    "\n",
    "**Potential issues to check:**\n",
    "1. Missing city names in the raw data\n",
    "2. Incorrect node-to-city mapping\n",
    "3. Data cleaning issues in `build_migration_network_for_year`\n",
    "4. Index misalignment between adjacency matrix and city names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src directory to path\n",
    "notebook_dir = Path.cwd()\n",
    "if 'notebooks' in str(notebook_dir):\n",
    "    src_dir = notebook_dir.parent\n",
    "else:\n",
    "    src_dir = notebook_dir / 'src'\n",
    "\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "from config import BaseConfig\n",
    "from utils.graph import build_migration_network_for_year\n",
    "\n",
    "config = BaseConfig()\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 169989\n",
      "\n",
      "Column names:\n",
      "['current_province', 'current_city', 'current_county', 'current_members_live_with', 'gender', 'year_born', 'edu_level', 'hometown_code', 'hometown', 'year_current_flow', 'month_current_flow', 'average_family_cost_per_month', 'average_family_income_per_month', 'year_first_flow', 'month_first_flow', 'first_flow_code', 'first_flow_location', 'num_flows_total', 'if_change_household_local', 'if_stay', 'how_long_to_stay', 'pc_key', 'hometown_Name_Province', 'hometown_Name_Prefecture', 'hometown_Name_County', 'hometown_lon', 'hometown_lat', 'first_Name_Province', 'first_Name_Prefecture', 'first_Name_County', 'first_lon', 'first_lat', 'current_lon', 'current_lat']\n",
      "\n",
      "Missing values in key columns:\n",
      "  current_city: 0 (0.0%)\n",
      "  hometown_Name_Prefecture: 17600 (10.4%)\n",
      "  first_Name_Prefecture: 33994 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "# Load migration data\n",
    "df = pd.read_csv(config.data_csv_path)\n",
    "\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Check for missing values in city-related columns\n",
    "print(f\"\\nMissing values in key columns:\")\n",
    "city_cols = ['current_city', 'hometown_Name_Prefecture', 'first_Name_Prefecture']\n",
    "for col in city_cols:\n",
    "    if col in df.columns:\n",
    "        missing = df[col].isna().sum()\n",
    "        print(f\"  {col}: {missing} ({missing/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine Network Building for Year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network for year 2015:\n",
      "  Nodes: 378\n",
      "  Edges: 5486\n",
      "\n",
      "Node types:\n",
      "  Type: <class 'str'>\n",
      "\n",
      "First 20 nodes:\n",
      "  0: '鹰潭市' (type: str)\n",
      "  1: '南昌市' (type: str)\n",
      "  2: '深圳市' (type: str)\n",
      "  3: '九江市' (type: str)\n",
      "  4: '保定市' (type: str)\n",
      "  5: '吉林市' (type: str)\n",
      "  6: '第十师' (type: str)\n",
      "  7: '赣州市' (type: str)\n",
      "  8: nan (type: float)\n",
      "  9: '菏泽市' (type: str)\n",
      "  10: '苏州市' (type: str)\n",
      "  11: '温州市' (type: str)\n",
      "  12: '莆田市' (type: str)\n",
      "  13: '开封市' (type: str)\n",
      "  14: '百色市' (type: str)\n",
      "  15: '阜新市' (type: str)\n",
      "  16: '延边朝鲜族自治州' (type: str)\n",
      "  17: '延边州' (type: str)\n",
      "  18: '绥化市' (type: str)\n",
      "  19: '鞍山市' (type: str)\n"
     ]
    }
   ],
   "source": [
    "# Test with year 2015 (one of the years being processed)\n",
    "TEST_YEAR = 2015\n",
    "\n",
    "# Build network using the utility function\n",
    "G = build_migration_network_for_year(df, TEST_YEAR)\n",
    "\n",
    "print(f\"Network for year {TEST_YEAR}:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"\\nNode types:\")\n",
    "print(f\"  Type: {type(list(G.nodes())[0])}\")\n",
    "\n",
    "# Get list of nodes\n",
    "node_list = list(G.nodes())\n",
    "print(f\"\\nFirst 20 nodes:\")\n",
    "for i, node in enumerate(node_list[:20]):\n",
    "    print(f\"  {i}: {repr(node)} (type: {type(node).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check for NaN Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node quality check:\n",
      "  Total nodes: 378\n",
      "  NaN nodes: 1\n",
      "  None nodes: 0\n",
      "  Valid nodes: 377\n",
      "\n",
      "⚠️ Found 1 NaN nodes!\n",
      "Sample NaN nodes: [nan]\n"
     ]
    }
   ],
   "source": [
    "# Count how many nodes are NaN or None\n",
    "nan_count = 0\n",
    "none_count = 0\n",
    "nan_nodes = []\n",
    "\n",
    "for node in node_list:\n",
    "    if pd.isna(node):\n",
    "        nan_count += 1\n",
    "        nan_nodes.append(node)\n",
    "    elif node is None:\n",
    "        none_count += 1\n",
    "    elif str(node).lower() == 'nan':\n",
    "        nan_count += 1\n",
    "        nan_nodes.append(node)\n",
    "\n",
    "print(f\"Node quality check:\")\n",
    "print(f\"  Total nodes: {len(node_list)}\")\n",
    "print(f\"  NaN nodes: {nan_count}\")\n",
    "print(f\"  None nodes: {none_count}\")\n",
    "print(f\"  Valid nodes: {len(node_list) - nan_count - none_count}\")\n",
    "\n",
    "if nan_nodes:\n",
    "    print(f\"\\n⚠️ Found {len(nan_nodes)} NaN nodes!\")\n",
    "    print(f\"Sample NaN nodes: {nan_nodes[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute TEU and Check Top Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEU statistics:\n",
      "  Min: 1\n",
      "  Max: 6086\n",
      "  Mean: 85\n",
      "  Median: 38\n",
      "\n",
      "Top 10 nodes by TEU:\n",
      "Rank   Index    City Name                      TEU       \n",
      "============================================================\n",
      "1      8        nan                            6086      \n",
      "2      41       '北京市'                          864       \n",
      "3      31       '上海市'                          771       \n",
      "4      2        '深圳市'                          561       \n",
      "5      23       '重庆市'                          527       \n",
      "6      195      '广州市'                          526       \n",
      "7      20       '天津市'                          465       \n",
      "8      167      '成都市'                          358       \n",
      "9      10       '苏州市'                          357       \n",
      "10     138      '郑州市'                          335       \n"
     ]
    }
   ],
   "source": [
    "# Convert to adjacency matrix\n",
    "adj_matrix = nx.to_numpy_array(G, weight='weight')\n",
    "\n",
    "# Compute TEU (node strength)\n",
    "out_strength = adj_matrix.sum(axis=1)\n",
    "in_strength = adj_matrix.sum(axis=0)\n",
    "teu = out_strength + in_strength\n",
    "\n",
    "print(f\"TEU statistics:\")\n",
    "print(f\"  Min: {teu.min():.0f}\")\n",
    "print(f\"  Max: {teu.max():.0f}\")\n",
    "print(f\"  Mean: {teu.mean():.0f}\")\n",
    "print(f\"  Median: {np.median(teu):.0f}\")\n",
    "\n",
    "# Get top 10 indices by TEU\n",
    "top_10_indices = np.argsort(teu)[-10:][::-1]\n",
    "\n",
    "print(f\"\\nTop 10 nodes by TEU:\")\n",
    "print(f\"{'Rank':<6} {'Index':<8} {'City Name':<30} {'TEU':<10}\")\n",
    "print(\"=\"*60)\n",
    "for rank, idx in enumerate(top_10_indices, 1):\n",
    "    city_name = node_list[idx]\n",
    "    print(f\"{rank:<6} {idx:<8} {repr(city_name):<30} {teu[idx]:<10.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Investigate Raw Data for NaN Nodes"
   ]
  },
  {
   "cell_type": "code",
   "source": "print(\"Analyzing raw data records that create NaN node...\\\\n\")\n\ndf_year = df[df['year_current_flow'] == TEST_YEAR].copy()\n\n# Find records where current_city is NaN (creates outgoing edges from NaN)\nnan_current = df_year[df_year['current_city'].isna()].copy()\nprint(f\"Records with NaN current_city: {len(nan_current)}\")\n\n# Find records where hometown is NaN (creates incoming edges to NaN)\nnan_hometown = df_year[df_year['hometown_Name_Prefecture'].isna()].copy()\nprint(f\"Records with NaN hometown: {len(nan_hometown)}\")\n\nprint(f\"\\\\n{'='*60}\")\nprint(\"What does NaN current_city represent?\")\nprint(f\"{'='*60}\")\n\nif len(nan_current) > 0:\n    # Check if these people have ANY location data\n    print(f\"\\\\nLocation data availability for NaN current_city records:\")\n    print(f\"  Has current_province: {nan_current['current_province'].notna().sum()} / {len(nan_current)}\")\n    print(f\"  Has current_county: {nan_current['current_county'].notna().sum()} / {len(nan_current)}\")\n    print(f\"  Has current_lon/lat: {nan_current['current_lon'].notna().sum()} / {len(nan_current)}\")\n    \n    # Show sample provinces/counties\n    if nan_current['current_province'].notna().sum() > 0:\n        print(f\"\\\\n  Top provinces for NaN current_city:\")\n        print(nan_current['current_province'].value_counts().head(10))\n    \n    if nan_current['current_county'].notna().sum() > 0:\n        print(f\"\\\\n  Top counties for NaN current_city:\")\n        print(nan_current['current_county'].value_counts().head(10))\n    \n    # Where are they coming from?\n    print(f\"\\\\n  Where are these people coming from (hometown)?\")\n    if 'hometown_Name_Prefecture' in nan_current.columns:\n        print(nan_current['hometown_Name_Prefecture'].value_counts().head(10))\n\nprint(f\"\\\\n{'='*60}\")\nprint(\"What does NaN hometown represent?\")\nprint(f\"{'='*60}\")\n\nif len(nan_hometown) > 0:\n    # Where are they going?\n    print(f\"\\\\nLocation data for NaN hometown records:\")\n    print(f\"  Current cities (where they're going):\")\n    print(nan_hometown['current_city'].value_counts().head(10))\n    \n    # Check if they have ANY hometown data\n    print(f\"\\\\n  Has hometown_province: {nan_hometown['hometown'].notna().sum()} / {len(nan_hometown)}\")\n    print(f\"  Has first_flow location: {nan_hometown['first_Name_Prefecture'].notna().sum()} / {len(nan_hometown)}\")\n\nprint(f\"\\\\n{'='*60}\")\nprint(\"INTERPRETATION\")\nprint(f\"{'='*60}\")\nprint(\"\\\\nThe NaN node represents:\")\nprint(\"  1. People whose current city is unknown (missing data)\")\nprint(\"  2. People whose hometown is unknown (missing data)\")\nprint(\"\\\\nThis could be due to:\")\nprint(\"  - Incomplete survey responses\")\nprint(\"  - Data entry errors\")\nprint(\"  - Privacy redactions\")\nprint(\"  - Coding issues in data collection\")\nprint(\"\\\\nRecommendation:\")\nprint(\"  → Filter out these records OR\")\nprint(\"  → Impute missing cities based on province/county data\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 13. Analyze What NaN Represents",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if nan_nodes and len(connected_cities) > 0:\n    print(\"Creating map visualization...\\n\")\n    \n    # Load city coordinates\n    city_coords_map = {}\n    for city in connected_cities:\n        city_data = df[df['current_city'] == city][['current_lon', 'current_lat']].dropna()\n        if len(city_data) == 0:\n            # Try hometown\n            city_data = df[df['hometown_Name_Prefecture'] == city][['hometown_lon', 'hometown_lat']].dropna()\n            if len(city_data) > 0:\n                city_coords_map[city] = (city_data.iloc[0]['hometown_lon'], city_data.iloc[0]['hometown_lat'])\n        else:\n            city_coords_map[city] = (city_data.iloc[0]['current_lon'], city_data.iloc[0]['current_lat'])\n    \n    print(f\"Found coordinates for {len(city_coords_map)} / {len(connected_cities)} cities\")\n    \n    # Create the map\n    fig, ax = plt.subplots(figsize=(18, 14))\n    \n    # Load China provinces shapefile\n    try:\n        china_map = gpd.read_file(config.china_provinces_path)\n        china_map.plot(ax=ax, color='#f0f0f0', edgecolor='#d9d9d9', linewidth=0.8)\n    except Exception as e:\n        print(f\"Warning: Could not load China map shapefile: {e}\")\n        print(\"Continuing without background map...\")\n    \n    ax.set_title(f\"Migration Flows Connected to NaN Node (Year {TEST_YEAR})\", \n                 fontsize=20, fontweight='bold', pad=20)\n    \n    # Draw cities connected to NaN\n    for city, (lon, lat) in city_coords_map.items():\n        if lon < 70 or lon > 140 or lat < 10 or lat > 60:\n            continue  # Skip bad coordinates\n        \n        flow = city_flows.get(city, 0)\n        size = min(flow * 5 + 100, 1000)  # Size based on flow volume\n        \n        # Color by incoming vs outgoing\n        is_incoming = any(u == city for u, v, _ in incoming_edges if not pd.isna(u))\n        is_outgoing = any(v == city for u, v, _ in outgoing_edges if not pd.isna(v))\n        \n        if is_incoming and is_outgoing:\n            color = '#9333ea'  # Purple - both directions\n        elif is_incoming:\n            color = '#ef4444'  # Red - incoming (people going TO NaN from this city)\n        else:\n            color = '#3b82f6'  # Blue - outgoing (people from NaN going to this city)\n        \n        ax.scatter(lon, lat, s=size, c=color, edgecolors='white', \n                   linewidth=2, zorder=5, alpha=0.7)\n        \n        # Label top 10 cities\n        if flow >= sorted(city_flows.values(), reverse=True)[min(9, len(city_flows)-1)]:\n            ax.text(lon + 0.5, lat + 0.3, f\"{city}\\\\n({flow})\", \n                    fontsize=10, fontweight='bold', color='#333333', \n                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7),\n                    zorder=6)\n    \n    # Add legend\n    from matplotlib.lines import Line2D\n    legend_elements = [\n        Line2D([0], [0], marker='o', color='w', markerfacecolor='#ef4444', \n               markersize=12, label=f'To NaN (incoming)'),\n        Line2D([0], [0], marker='o', color='w', markerfacecolor='#3b82f6', \n               markersize=12, label=f'From NaN (outgoing)'),\n        Line2D([0], [0], marker='o', color='w', markerfacecolor='#9333ea', \n               markersize=12, label='Both directions'),\n    ]\n    ax.legend(handles=legend_elements, loc='upper right', fontsize=12, framealpha=0.9)\n    \n    # Add text annotation\n    text_info = f\"Total migration flow: {sum(city_flows.values())} people\\\\n\"\n    text_info += f\"Connected cities: {len(city_coords_map)}\\\\n\"\n    text_info += f\"Incoming: {len(incoming_edges)} | Outgoing: {len(outgoing_edges)}\"\n    ax.text(0.02, 0.98, text_info, transform=ax.transAxes, \n            fontsize=11, verticalalignment='top',\n            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n    \n    # Focus on mainland China\n    ax.set_xlim(73, 136)\n    ax.set_ylim(18, 54)\n    ax.set_xlabel('Longitude', fontsize=12)\n    ax.set_ylabel('Latitude', fontsize=12)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\\\n✓ Map visualization complete!\")\nelse:\n    print(\"Cannot create map: No NaN nodes or no connected cities with coordinates.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import geopandas as gpd\nimport matplotlib.patches as patches\n\n# Check if we have NaN nodes to visualize\nif nan_nodes:\n    print(f\"Visualizing connections for NaN node on China map...\\n\")\n    \n    # Get the NaN node (just first one if multiple)\n    nan_node = nan_nodes[0]\n    \n    # Get all edges involving the NaN node\n    incoming_edges = list(G.in_edges(nan_node, data=True))\n    outgoing_edges = list(G.out_edges(nan_node, data=True))\n    \n    print(f\"NaN Node Statistics:\")\n    print(f\"  Incoming edges: {len(incoming_edges)}\")\n    print(f\"  Outgoing edges: {len(outgoing_edges)}\")\n    print(f\"  Total edges: {len(incoming_edges) + len(outgoing_edges)}\")\n    \n    # Get cities connected to NaN node\n    connected_cities = set()\n    for u, v, data in incoming_edges:\n        if not pd.isna(u):\n            connected_cities.add(u)\n    for u, v, data in outgoing_edges:\n        if not pd.isna(v):\n            connected_cities.add(v)\n    \n    print(f\"  Unique cities connected: {len(connected_cities)}\")\n    \n    # Get top cities by flow\n    city_flows = {}\n    for u, v, data in incoming_edges:\n        if not pd.isna(u):\n            weight = data.get('weight', 1)\n            city_flows[u] = city_flows.get(u, 0) + weight\n    for u, v, data in outgoing_edges:\n        if not pd.isna(v):\n            weight = data.get('weight', 1)\n            city_flows[v] = city_flows.get(v, 0) + weight\n    \n    top_cities = sorted(city_flows.items(), key=lambda x: x[1], reverse=True)[:20]\n    print(f\"\\n  Top 20 cities by flow with NaN node:\")\n    for rank, (city, flow) in enumerate(top_cities, 1):\n        print(f\"    {rank}. {city}: {flow} people\")\n    \nelse:\n    print(\"No NaN nodes found to visualize.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 12. Visualize NaN Node Connections on China Map",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking raw data for year 2015...\n",
      "\n",
      "Total records for 2015: 18651\n",
      "\n",
      "Current city analysis:\n",
      "  Total values: 18651\n",
      "  Missing (NaN): 0\n",
      "  Unique cities: 343\n",
      "\n",
      "Hometown city analysis:\n",
      "  Total values: 18651\n",
      "  Missing (NaN): 1920\n",
      "  Unique cities: 327\n"
     ]
    }
   ],
   "source": [
    "# If we found NaN nodes, let's see where they come from in the raw data\n",
    "print(\"Checking raw data for year 2015...\\n\")\n",
    "\n",
    "# Filter for year 2015\n",
    "df_year = df[df['year_current_flow'] == TEST_YEAR].copy()\n",
    "\n",
    "print(f\"Total records for {TEST_YEAR}: {len(df_year)}\")\n",
    "\n",
    "# Check current_city column\n",
    "print(f\"\\nCurrent city analysis:\")\n",
    "print(f\"  Total values: {len(df_year)}\")\n",
    "print(f\"  Missing (NaN): {df_year['current_city'].isna().sum()}\")\n",
    "print(f\"  Unique cities: {df_year['current_city'].nunique()}\")\n",
    "\n",
    "# Check hometown column\n",
    "print(f\"\\nHometown city analysis:\")\n",
    "if 'hometown_Name_Prefecture' in df_year.columns:\n",
    "    print(f\"  Total values: {len(df_year)}\")\n",
    "    print(f\"  Missing (NaN): {df_year['hometown_Name_Prefecture'].isna().sum()}\")\n",
    "    print(f\"  Unique cities: {df_year['hometown_Name_Prefecture'].nunique()}\")\n",
    "\n",
    "# Show sample of records with missing current_city\n",
    "missing_current = df_year[df_year['current_city'].isna()]\n",
    "if len(missing_current) > 0:\n",
    "    print(f\"\\n⚠️ Found {len(missing_current)} records with missing current_city\")\n",
    "    print(f\"\\nSample records:\")\n",
    "    cols_to_show = ['current_city', 'hometown_Name_Prefecture', 'first_Name_Prefecture', \n",
    "                    'year_current_flow', 'current_members_live_with']\n",
    "    print(missing_current[cols_to_show].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trace How Network is Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual network building trace:\n",
      "\n",
      "Function source code:\n",
      "============================================================\n",
      "def build_migration_network_for_year(df: pd.DataFrame, year: int) -> nx.DiGraph:\n",
      "    \"\"\"\n",
      "    Build directed migration network for a specific year.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    df : DataFrame\n",
      "        Migration data\n",
      "    year : int\n",
      "        Year to analyze\n",
      "        either year_first_flow or year_current_flow matches this year.\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    G : nx.DiGraph\n",
      "        Network with nodes (cities) and edges (migration flows)\n",
      "    \"\"\"\n",
      "    G = nx.DiGraph()\n",
      "    \n",
      "    # Filter data for the year\n",
      "    year_data = df[\n",
      "        ((df['year_first_flow'] == year) | (df['year_current_flow'] == year))\n",
      "    ]\n",
      "\n",
      "    \n",
      "    for _, row in year_data.iterrows():\n",
      "        # Extract city names and coordinates\n",
      "        hometown = row['hometown_Name_Prefecture']\n",
      "        first_city = row['first_Name_Prefecture']\n",
      "        current_city = row['current_city']\n",
      "        \n",
      "        hometown_pos = (row['hometown_lon'], row['hometown_lat'])\n",
      "        first_pos = (row['first_lon'], row['first_lat'])\n",
      "        current_pos = (row['current_lon'], row['current_lat'])\n",
      "        \n",
      "        # Add nodes with positions\n",
      "        G.add_node(hometown, pos=hometown_pos, \n",
      "                  lon=row['hometown_lon'], lat=row['hometown_lat'])\n",
      "        G.add_node(first_city, pos=first_pos,\n",
      "                  lon=row['first_lon'], lat=row['first_lat'])\n",
      "        G.add_node(current_city, pos=current_pos,\n",
      "                  lon=row['current_lon'], lat=row['current_lat'])\n",
      "        \n",
      "        # Add edges for flows in this year\n",
      "        if row['year_first_flow'] == year and hometown != first_city:\n",
      "            if G.has_edge(hometown, first_city):\n",
      "                G[hometown][first_city]['weight'] += 1\n",
      "            else:\n",
      "                G.add_edge(hometown, first_city, weight=1)\n",
      "        \n",
      "        if row['year_current_flow'] == year and first_city != current_city:\n",
      "            if G.has_edge(first_city, current_city):\n",
      "                G[first_city][current_city]['weight'] += 1\n",
      "            else:\n",
      "                G.add_edge(first_city, current_city, weight=1)\n",
      "    \n",
      "    # Remove isolated nodes\n",
      "    G.remove_nodes_from(list(nx.isolates(G)))\n",
      "    \n",
      "    return G\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's manually trace through how the network is built\n",
    "print(\"Manual network building trace:\\n\")\n",
    "\n",
    "# Read the source code of build_migration_network_for_year\n",
    "import inspect\n",
    "source = inspect.getsource(build_migration_network_for_year)\n",
    "print(\"Function source code:\")\n",
    "print(\"=\"*60)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Check Edge Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking edges involving NaN nodes...\n",
      "\n",
      "Edges involving NaN nodes: 573\n",
      "\n",
      "Sample edges with NaN:\n",
      "  '南昌市' -> nan (weight=5)\n",
      "  '深圳市' -> nan (weight=2)\n",
      "  '九江市' -> nan (weight=3)\n",
      "  '保定市' -> nan (weight=5)\n",
      "  '吉林市' -> nan (weight=7)\n",
      "  '赣州市' -> nan (weight=9)\n",
      "  nan -> '赣州市' (weight=19)\n",
      "  nan -> '莆田市' (weight=3)\n",
      "  nan -> '黔东南苗族侗族自治州' (weight=4)\n",
      "  nan -> '大连市' (weight=32)\n",
      "\n",
      "Degree statistics for NaN node:\n",
      "  In-degree (weighted): 1322\n",
      "  Out-degree (weighted): 4764\n",
      "  Total strength: 6086\n"
     ]
    }
   ],
   "source": [
    "# Let's see what edges are being created with NaN nodes\n",
    "print(\"Checking edges involving NaN nodes...\\n\")\n",
    "\n",
    "# Get edges from the graph\n",
    "edges_with_nan = []\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if pd.isna(u) or pd.isna(v) or str(u).lower() == 'nan' or str(v).lower() == 'nan':\n",
    "        edges_with_nan.append((u, v, data.get('weight', 0)))\n",
    "\n",
    "print(f\"Edges involving NaN nodes: {len(edges_with_nan)}\")\n",
    "\n",
    "if edges_with_nan:\n",
    "    print(f\"\\nSample edges with NaN:\")\n",
    "    for u, v, w in edges_with_nan[:10]:\n",
    "        print(f\"  {repr(u)} -> {repr(v)} (weight={w})\")\n",
    "    \n",
    "    # Check degree of NaN node\n",
    "    for node in nan_nodes[:1]:  # Just check first NaN node\n",
    "        in_degree = G.in_degree(node, weight='weight')\n",
    "        out_degree = G.out_degree(node, weight='weight')\n",
    "        print(f\"\\nDegree statistics for NaN node:\")\n",
    "        print(f\"  In-degree (weighted): {in_degree}\")\n",
    "        print(f\"  Out-degree (weighted): {out_degree}\")\n",
    "        print(f\"  Total strength: {in_degree + out_degree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check Raw Data Records Creating NaN Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find records where either current_city or hometown is NaN\nprint(\"Records with NaN in migration flow:\\n\")\n\ndf_year = df[df['year_current_flow'] == TEST_YEAR].copy()\n\n# Records where current_city is NaN\nnan_current = df_year[df_year['current_city'].isna()]\nprint(f\"Records with NaN current_city: {len(nan_current)}\")\n\n# Records where hometown is NaN\nif 'hometown_Name_Prefecture' in df_year.columns:\n    nan_hometown = df_year[df_year['hometown_Name_Prefecture'].isna()]\n    print(f\"Records with NaN hometown: {len(nan_hometown)}\")\n    \n    # DETAILED ANALYSIS OF NaN HOMETOWN RECORDS\n    print(f\"\\n{'='*80}\")\n    print(\"DETAILED ANALYSIS: Why is hometown_Name_Prefecture NaN?\")\n    print(f\"{'='*80}\")\n    \n    if len(nan_hometown) > 0:\n        # Check what hometown-related data IS available\n        print(f\"\\nAvailability of hometown-related fields:\")\n        print(f\"  hometown_code: {nan_hometown['hometown_code'].notna().sum()} / {len(nan_hometown)} records\")\n        print(f\"  hometown (raw): {nan_hometown['hometown'].notna().sum()} / {len(nan_hometown)} records\")\n        print(f\"  hometown_Name_Province: {nan_hometown['hometown_Name_Province'].notna().sum()} / {len(nan_hometown)} records\")\n        print(f\"  hometown_Name_County: {nan_hometown['hometown_Name_County'].notna().sum()} / {len(nan_hometown)} records\")\n        print(f\"  hometown_lon: {nan_hometown['hometown_lon'].notna().sum()} / {len(nan_hometown)} records\")\n        print(f\"  hometown_lat: {nan_hometown['hometown_lat'].notna().sum()} / {len(nan_hometown)} records\")\n        \n        # Show sample of actual values for these fields\n        print(f\"\\n{'='*80}\")\n        print(\"Sample of NaN hometown records (showing all hometown-related fields):\")\n        print(f\"{'='*80}\")\n        hometown_cols = ['hometown_code', 'hometown', 'hometown_Name_Province', \n                         'hometown_Name_Prefecture', 'hometown_Name_County',\n                         'hometown_lon', 'hometown_lat', 'current_city']\n        print(nan_hometown[hometown_cols].head(20).to_string())\n        \n        # Check if there's a pattern in hometown_code\n        print(f\"\\n{'='*80}\")\n        print(\"Hometown codes for NaN prefecture records:\")\n        print(f\"{'='*80}\")\n        print(nan_hometown['hometown_code'].value_counts().head(20))\n        \n        # Check if there's a pattern in raw hometown field\n        print(f\"\\n{'='*80}\")\n        print(\"Raw hometown values for NaN prefecture records:\")\n        print(f\"{'='*80}\")\n        print(nan_hometown['hometown'].value_counts().head(20))\n        \n        # Check provinces\n        print(f\"\\n{'='*80}\")\n        print(\"Hometown provinces for NaN prefecture records:\")\n        print(f\"{'='*80}\")\n        print(nan_hometown['hometown_Name_Province'].value_counts().head(20))\n\n# Show distribution of these records\nif len(nan_current) > 0:\n    print(f\"\\nNaN current_city - Hometown distribution:\")\n    if 'hometown_Name_Prefecture' in df_year.columns:\n        hometown_dist = nan_current['hometown_Name_Prefecture'].value_counts().head(10)\n        print(hometown_dist)\n\nif 'hometown_Name_Prefecture' in df_year.columns and len(nan_hometown) > 0:\n    print(f\"\\n{'='*80}\")\n    print(\"NaN hometown - Current city distribution:\")\n    print(f\"{'='*80}\")\n    current_dist = nan_hometown['current_city'].value_counts().head(20)\n    print(current_dist)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Proposed Solutions"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Show COMPLETE records for people with NaN hometown to understand the full picture\nprint(\"=\"*80)\nprint(\"COMPLETE RECORDS: First 10 people with NaN hometown_Name_Prefecture\")\nprint(\"=\"*80)\n\nif 'nan_hometown' in locals() and len(nan_hometown) > 0:\n    # Display all columns for first 10 records\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', None)\n    pd.set_option('display.max_colwidth', 50)\n    \n    print(\"\\nShowing ALL fields for 10 sample records:\\n\")\n    sample_records = nan_hometown.head(10)\n    \n    for idx, (row_idx, row) in enumerate(sample_records.iterrows(), 1):\n        print(f\"\\n{'─'*80}\")\n        print(f\"Record #{idx} (Index: {row_idx})\")\n        print(f\"{'─'*80}\")\n        for col in df.columns:\n            value = row[col]\n            # Highlight NaN values\n            if pd.isna(value):\n                print(f\"  {col:<35} : ❌ NaN\")\n            else:\n                print(f\"  {col:<35} : {value}\")\n    \n    # Reset pandas display options\n    pd.reset_option('display.max_columns')\n    pd.reset_option('display.width')\n    pd.reset_option('display.max_colwidth')\n    \n    # Summary statistics\n    print(f\"\\n{'='*80}\")\n    print(\"PATTERN ANALYSIS\")\n    print(f\"{'='*80}\")\n    \n    # Check if NaN hometown is associated with certain provinces or regions\n    print(\"\\nDo these NaN hometown records have other location markers?\")\n    print(f\"  Have first_flow location: {nan_hometown['first_Name_Prefecture'].notna().sum()} / {len(nan_hometown)}\")\n    print(f\"  Have current location: {nan_hometown['current_city'].notna().sum()} / {len(nan_hometown)}\")\n    \n    # Check year patterns\n    print(f\"\\nYear patterns:\")\n    if 'year_first_flow' in nan_hometown.columns:\n        print(f\"  year_first_flow distribution:\")\n        print(nan_hometown['year_first_flow'].value_counts().head(10))\n    \n    # Check demographic patterns\n    print(f\"\\nDemographic patterns:\")\n    if 'gender' in nan_hometown.columns:\n        print(f\"  Gender: {nan_hometown['gender'].value_counts()}\")\n    if 'edu_level' in nan_hometown.columns:\n        print(f\"\\n  Education level:\")\n        print(nan_hometown['edu_level'].value_counts())\n        \nelse:\n    print(\"No NaN hometown records to analyze.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9.5. Examine Complete Records with NaN Hometown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIAGNOSTIC SUMMARY\n",
      "============================================================\n",
      "\n",
      "1. Data Quality Issues Found:\n",
      "   ✗ 1 NaN nodes in network (0.3%)\n",
      "   ✓ No missing current_city values\n",
      "\n",
      "2. Recommended Solutions:\n",
      "   Option A: Filter out NaN nodes when building network\n",
      "   Option B: Replace NaN with a placeholder (e.g., 'Unknown City')\n",
      "   Option C: Exclude records with missing city information\n",
      "\n",
      "3. Implementation:\n",
      "   Modify build_migration_network_for_year() to handle NaN values\n",
      "   Add data validation before creating edges\n",
      "\n",
      "4. Impact:\n",
      "   NaN node has TEU = 6086\n",
      "   This is 18.8% of total migration flow\n",
      "   Rank: #1 out of 378\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. Data Quality Issues Found:\")\n",
    "if nan_count > 0:\n",
    "    print(f\"   ✗ {nan_count} NaN nodes in network ({nan_count/len(node_list)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   ✓ No NaN nodes found\")\n",
    "\n",
    "if len(missing_current) > 0:\n",
    "    print(f\"   ✗ {len(missing_current)} records with missing current_city\")\n",
    "else:\n",
    "    print(f\"   ✓ No missing current_city values\")\n",
    "\n",
    "print(f\"\\n2. Recommended Solutions:\")\n",
    "print(\"   Option A: Filter out NaN nodes when building network\")\n",
    "print(\"   Option B: Replace NaN with a placeholder (e.g., 'Unknown City')\")\n",
    "print(\"   Option C: Exclude records with missing city information\")\n",
    "\n",
    "print(f\"\\n3. Implementation:\")\n",
    "print(\"   Modify build_migration_network_for_year() to handle NaN values\")\n",
    "print(\"   Add data validation before creating edges\")\n",
    "\n",
    "# Quantify impact\n",
    "if nan_count > 0 and len(nan_nodes) > 0:\n",
    "    nan_node_idx = node_list.index(nan_nodes[0])\n",
    "    nan_teu = teu[nan_node_idx]\n",
    "    print(f\"\\n4. Impact:\")\n",
    "    print(f\"   NaN node has TEU = {nan_teu:.0f}\")\n",
    "    print(f\"   This is {nan_teu/teu.sum()*100:.1f}% of total migration flow\")\n",
    "    print(f\"   Rank: #{len(teu) - np.searchsorted(np.sort(teu), nan_teu)} out of {len(teu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test Fix: Filter NaN Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fix: Exclude NaN nodes\n",
      "\n",
      "Original records: 18651\n",
      "Clean records: 16731\n",
      "Removed: 1920 (10.3%)\n",
      "\n",
      "Cleaned network:\n",
      "  Nodes: 376\n",
      "  Edges: 5552\n",
      "  NaN nodes: 0\n",
      "\n",
      "Top 10 nodes in cleaned network:\n",
      "  1. 重庆市: TEU=1618\n",
      "  2. 北京市: TEU=603\n",
      "  3. 上海市: TEU=458\n",
      "  4. 南宁市: TEU=426\n",
      "  5. 哈尔滨市: TEU=412\n",
      "  6. 合肥市: TEU=392\n",
      "  7. 成都市: TEU=385\n",
      "  8. 天津市: TEU=369\n",
      "  9. 石家庄市: TEU=360\n",
      "  10. 郑州市: TEU=346\n"
     ]
    }
   ],
   "source": [
    "# Test solution: rebuild network excluding NaN nodes\n",
    "print(\"Testing fix: Exclude NaN nodes\\n\")\n",
    "\n",
    "# Filter data to exclude NaN cities\n",
    "df_year_clean = df_year[\n",
    "    df_year['current_city'].notna() & \n",
    "    df_year['hometown_Name_Prefecture'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"Original records: {len(df_year)}\")\n",
    "print(f\"Clean records: {len(df_year_clean)}\")\n",
    "print(f\"Removed: {len(df_year) - len(df_year_clean)} ({(len(df_year) - len(df_year_clean))/len(df_year)*100:.1f}%)\")\n",
    "\n",
    "# Rebuild network with clean data\n",
    "# This is a simple test - actual fix should be in the build function\n",
    "G_clean = nx.DiGraph()\n",
    "\n",
    "for _, row in df_year_clean.iterrows():\n",
    "    current = row['current_city']\n",
    "    hometown = row['hometown_Name_Prefecture']\n",
    "    \n",
    "    # Skip if either is NaN (double check)\n",
    "    if pd.isna(current) or pd.isna(hometown):\n",
    "        continue\n",
    "    \n",
    "    # Add edge\n",
    "    if G_clean.has_edge(hometown, current):\n",
    "        G_clean[hometown][current]['weight'] += 1\n",
    "    else:\n",
    "        G_clean.add_edge(hometown, current, weight=1)\n",
    "\n",
    "print(f\"\\nCleaned network:\")\n",
    "print(f\"  Nodes: {G_clean.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G_clean.number_of_edges()}\")\n",
    "\n",
    "# Check for NaN nodes in cleaned network\n",
    "node_list_clean = list(G_clean.nodes())\n",
    "nan_in_clean = sum(1 for node in node_list_clean if pd.isna(node))\n",
    "print(f\"  NaN nodes: {nan_in_clean}\")\n",
    "\n",
    "# Compute TEU for clean network\n",
    "adj_clean = nx.to_numpy_array(G_clean, weight='weight')\n",
    "teu_clean = adj_clean.sum(axis=1) + adj_clean.sum(axis=0)\n",
    "\n",
    "top_10_clean = np.argsort(teu_clean)[-10:][::-1]\n",
    "print(f\"\\nTop 10 nodes in cleaned network:\")\n",
    "for rank, idx in enumerate(top_10_clean, 1):\n",
    "    city = node_list_clean[idx]\n",
    "    print(f\"  {rank}. {city}: TEU={teu_clean[idx]:.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "migra-net-china (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}